
[spider_core]
# 默认关注与被关注列表每页的大小（知乎目前是20条一页）
pageSize = 20
# 爬虫动作时间间隔（单位：秒）
scrapeTimeInterval = 2
# 正在关注页面时最大爬取页面范围(若为负数则代表不作限制)
followingPageMax = 200
# 关注着页面最大爬取页面范围(若为负数则代表不作限制)
followerPageMax = 100
# 是否分析正在关注列表(1代表是，0代表否)
analyseFollowingList = 1
# 是否分析关注者列表(1代表是，0代表否)
analyse_FollowerList = 1
# 用户信息抓取线程数量
userInfoScrapeThreadNum = 8
# 用户列表抓取线程数量
userListScrapeThreadNum = 8
# 是否使用代理(1代表是，0代表否)
isProxyEnable = 1

# 每个代理最大请求次数
proxyUsageMax = 10000
# 发生网络异常重试次数
networkReconnectTimes = 3
# 发生响应异常重试次数
responseErrorRetryTimes = 5
# 网络连接超时（单位：秒）
connectTimeout = 30

# 已分析用户信息的用户 token 缓存列表大小
maxAnalysedCacheQueueSize = 1000
# 已分析用户信息的缓存列表保留大小
remainAnalysedCacheQueueSize = 10
# 未分析用户信息的用户 token 缓存列表大小
maxCacheQueueSize = 1000
# 未分析用户信息的用户 token 缓存列表保留大小
remainCacheQueueSize = 10

# 数据库配置
dbHost = localhost
dbUsername = root
dbPassword = LJQ20110627
dbDatabase = zhihu_spider_test
dbCharset = utf8

# 爬虫起始token
startToken =